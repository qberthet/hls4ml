{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 9: Vitis Accel\n",
    "\n",
    "In the previous sections we've seen how to deploy a model on a [pynq-z2 board](http://www.pynq.io/) with the `VivadoAccelerator` backend. In this section, we introduce the `VitisAccelerator` backend of `hls4ml`, an alternative workflow for deploying models that uses AMD's Vitis Accel workflow. This time, we will deploy the model on an [Alveo U55C Accelerator Card](https://www.xilinx.com/products/boards-and-kits/alveo/u55c.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 06:16:51.322811: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "import os\n",
    "\n",
    "# os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model\n",
    "Load the model from `part4: quantization` (note you need to have trained the model in part 4 first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 06:16:59.043487: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model_3/KERAS_check_best_model.h5', custom_objects=co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to hls4ml\n",
    "Similar to part 7, We'll convert our model into `hls4ml`, targeting the `backend='VitisAccelerator'` backend this time around. This backend wraps the HLS model and adds a CPU/MCU program that drives the FPGA. We also specify `board='alveo-u55c'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: fc1, layer type: QDense, input shapes: [[None, 16]], output shape: [None, 64]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: fc2, layer type: QDense, input shapes: [[None, 64]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc3, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu3, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 5]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "-----------------------------------\n",
      "Model\n",
      "  Precision:         fixed<16,6>\n",
      "  ReuseFactor:       1\n",
      "  Strategy:          Latency\n",
      "  BramFactor:        1000000000\n",
      "  TraceOutput:       False\n",
      "LayerName\n",
      "  fc1_input\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  fc1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<6,1,TRN,WRAP,0>\n",
      "      bias:          fixed<6,1,TRN,WRAP,0>\n",
      "  fc1_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  relu1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        ufixed<6,0,RND_CONV,SAT,0>\n",
      "  fc2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<6,1,TRN,WRAP,0>\n",
      "      bias:          fixed<6,1,TRN,WRAP,0>\n",
      "  fc2_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  relu2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        ufixed<6,0,RND_CONV,SAT,0>\n",
      "  fc3\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<6,1,TRN,WRAP,0>\n",
      "      bias:          fixed<6,1,TRN,WRAP,0>\n",
      "  fc3_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  relu3\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        ufixed<6,0,RND_CONV,SAT,0>\n",
      "  output\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<6,1,TRN,WRAP,0>\n",
      "      bias:          fixed<6,1,TRN,WRAP,0>\n",
      "  output_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  softmax\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    exp_table_t:     ap_fixed<18,8>\n",
      "    inv_table_t:     ap_fixed<18,4>\n",
      "-----------------------------------\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: fc1, layer type: QDense, input shapes: [[None, 16]], output shape: [None, 64]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: fc2, layer type: QDense, input shapes: [[None, 64]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc3, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu3, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 5]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "\n",
      "\n",
      "Writing Accelerator code\n",
      "WARNING: You set a Part that does not correspond to the Board you specified.The correct Part is now set.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "local_module_dir = os.path.join(\"/home/jovyan/work/hls4ml\") # This should be changed the path of the local modified version of HLS4ML containing Vitis Accel backend\n",
    "sys.path.insert(0, local_module_dir)\n",
    "\n",
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model,\n",
    "    hls_config=config,\n",
    "    output_dir='model_3/hls4ml_prj_vitis_accel',\n",
    "    backend='VitisAccelerator',\n",
    "    board='alveo-u55c',\n",
    "    num_kernel=4,\n",
    "    num_thread=8,\n",
    "    batchsize=8192\n",
    ")\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see which baords are supported in the [documentation](https://fastmachinelearning.org/hls4ml/advanced/accelerator.html). The `VitisAccelerator` backend has a different `AcceleratorConfig` section of the configuration. Here we can change some details of the Vitis Accel project.\n",
    "\n",
    "In this example, we set `'num_kernel=4'`, directing Vitis Accel to create 4 copies of the kernel on the FPGA. We also set `'num_thread=8'`, meaning that the host code will create 8 threads to drive the FPGA. For a multi-core CPU, this improves throughput by increasing the speed at which data is written to the FPGA memory.\n",
    "\n",
    "The `create_initial_config` method (of any backend) can be used to create a template dictionary with the default parameters that you can use as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part:                xcvu13p-flga2577-2-e\n",
      "ClockPeriod:         5\n",
      "IOType:              io_parallel\n",
      "HLSConfig\n",
      "AcceleratorConfig\n",
      "  Board:             alveo-u55c\n",
      "  Num_Kernel:        1\n",
      "  Num_Thread:        1\n",
      "  Batchsize:         8192\n"
     ]
    }
   ],
   "source": [
    "plotting.print_dict(hls4ml.backends.get_backend('VitisAccelerator').create_initial_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "Run the CPU emulation of the hls4ml NN and save the file to compare against the hardware result later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_test = np.load('X_test.npy')\n",
    "y_hls = hls_model.predict(np.ascontiguousarray(X_test))\n",
    "np.save('model_3/y_hls.npy', y_hls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
